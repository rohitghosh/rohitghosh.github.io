<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Iota &middot; Imaginary Reality
    
  </title>

  <link rel="stylesheet" href="/styles.css">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="alternate" type="application/atom+xml" title="Iota" href="/atom.xml">
</head>


  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83853401-1', 'auto');
  ga('send', 'pageview');

</script>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">Iota</a>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/about">About</a></small>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/archive">Archive</a></small>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/atom.xml">Feed</a></small>
          
        </h3>
      </header>

      <main>
        <!-- <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="//2017/01/25/overlapping-chromosome-segmentation/">
        Segmenting Overlapping Chromosomes using Deep Learning
      </a>
    </h1>

    <span class="post-date">25 Jan 2017</span>

    <p>After my last <a href="https://rohitghosh.github.io/2016/12/10/NYC-cabs-data/">post</a> on optimization of earnings by cab drivers as they drive through New York City – this post explores using deep learning aka Artificial Intelligence to segment out overlapping chromosomes on slides used for cytogenetic studies. The project is part of a set of open problems posted on <a href="http://ai-on.org/">AI ON website</a>. The repo for the project is also available on my <a href="https://github.com/rohitghosh/chromosome_segementation">GitHub</a>. We’re still working on it and would love if any of you would like to join and contribute !</p>

<h3 id="cytogenetics">Cytogenetics</h3>

<p>Cytogenetics is the study of cells, more so chromosomes and their structure and changes.Changes to chromosome structure can disrupt genes, causing the proteins made from disrupted genes to be missing or faulty. Depending on size, location, and timing, structural changes in chromosomes can lead to birth defects, syndromes or even cancer.</p>

<p>The importance of separating overlapping chromosomes can be understood in terms of the orders of difficulty involved in manually segmenting them. In cytogenetics, experiments typically starts from chromosomal preparations fixed on glass slides. Occasionally a chromosome can fall on another one, yielding overlapping chromosomes in the image. Before computers and images processing with photography, chromosomes were cut from a paper picture and then classified (at least two paper pictures were required when chromosomes are overlapping). More recently, automatic segmentation methods were developed to overcome this problem. Most of the time these methods rely on a geometric analysis of the chromosome contour and require some human intervention when partial overlap occurs.</p>

<h3 id="semantic-segmentation--u-net">Semantic Segmentation &amp; U Net</h3>

<p>Semantic segmentation for computer vision refers to segmenting out objects from images. Semantic because objects need to be segmented out with respect to surrounding objects/ background in image. That is, algorithm should be able to segment a tree even if it’s taken close-up or at some distance, and not based on absolute cor-ordinates of the object in the image.
<img src="/images/chromosome_seg/semantic_segmnentation.jpeg" alt="placeholder" style="margin:auto; display:inline; float:right;" /></p>

<p>So if a net needs to segment out a tree – it would first need to understand what features of an object make it look like tree. Like leaves, branches stem and in a particular arrangement - leaves on branches, branching out from trunk only makes it look like a tree. But only understanding features won’t help – it would need to map the features learnt to an image and segment only the matching part – to mark out a tree.</p>

<p>This is exactly what a U Net does – it uses convolutional feature maps to first learn the features as it progressively downsamples the image size. After that, the learnt feature maps are progressively upsampled and in each step they are merged with feature maps of same size from the downsampling phase. The merging step helps the net to spatially place the learn features back into the image.
<img src="/images/chromosome_seg/unet.png" alt="placeholder" style="margin:auto; display:inline;" /></p>

<p>As the image above explains,input image consist of 3 channels (RGB) and is passed through 3 convolutional layers before being downsampled to half the size. After extracting enough features, with dimensions of 28 x 28, they maps are upsampled and in each step merged with the feature map of the corresponding step in downsampling path.</p>

<h3 id="training-methodologies">Training Methodologies</h3>

<p>Each of the annotated images consists of 4 classes, where class 4 is the common region between 2 overlapping chromosomes. The classes 1 &amp; 2 , are non-overlapping part of each of the chromosomes. Class 0 is the background
The performance of the net was observed using mean_dice_score. It was computed as </p>

<blockquote>
  <p><code class="highlighter-rouge">dice_score = 2*I/(GT + PL)</code></p>

  <p>I  = number of pixels predicted correctly except background</p>

  <p>GT = number of pixels which belong to ground-truth except background</p>

  <p>PL = number of pixels in predicted image except background.</p>
</blockquote>

<p>There were 2 methods of training attempted
•	Treating all the classes independently (param <code class="highlighter-rouge">combine_label = True</code> in segmentation.py)
•	Treating Class 1 &amp; Class 2 as same i.e. Class 1 and Class 3 as Class 2 (param combine_label = False in segmentation.py)Assumption being the non-overlapping parts inherently aren’t different in each chromosomes. Then we can apply conventional CV methods like watershed algorithm to distinguish between the non-overlapping blobs</p>

<h3 id="results">Results</h3>

<p>The results looked a lot of promising where my validation set was first 200 images from 20% of the total dataset. With combined labels, could reach a dice score as high as 0.97. Without combined labels, could reach a dice score as high as 0.81.</p>

<h4 id="predictions-for-combinedlabel">Predictions for combined_label</h4>
<p><img src="/images/chromosome_seg/Vis_combined_label_2.png" alt="predict_combined_new" />
<img src="/images/chromosome_seg/Vis_combined_label_1.png" alt="predict_combined_new" /></p>

<h4 id="predictions-without-combining-labels">Predictions without combining labels</h4>
<p><img src="/images/chromosome_seg/Vis_non_combined_label_1.png" alt="predict_non_combined_new" />
<img src="/images/chromosome_seg/Vis_non_combined_label_2.png" alt="predict_non_combined_new" /></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="//2016/12/10/NYC-cabs-data/">
        Optimising Cab Routes In NYC Using Data
      </a>
    </h1>

    <span class="post-date">10 Dec 2016</span>

    <p>These days, on my cab rides, I have met some interesting folks driving the cabs. And, a lot of those times, when the driver was owner of the cab, our conversation tended towards to the ever-so-important question - “How to generate maximum revenue?”</p>

<p>Do I drive at night? Where do I start my trip? What do I optimize for – longer rides in a longer time or repeated shorter rides in the same time? How long do I drive? and alike questions. There’s a lot of other factors as well, apart from just money that can motivate a cab driver’s decisions - for the purpose of this study those are not addressed.</p>

<p>So, the idea was to design something very basic which could answer these questions and see the degree to which the algorithm would help the cab driver optimise, over and beyond his current earnings.
I had some access to cab data released by  NYC Taxi &amp; Limousine Commission from NYC for April ‘13 capturing drop-off and pick-up co-ordinates and time of the day for all cab drivers, along with the total fare split (fare + tips). Similar data for different time-period is available on <a href="https://www.kaggle.com/fivethirtyeight/uber-pickups-in-new-york-city">Kaggle</a> in case any of the readers are interested to undertake the exercise on their own. The entire script is available on <a href="/images/NYC_cabs_data/NYC_Cabs_Data.html">here</a>.</p>

<h3 id="interesting-insights">Interesting Insights</h3>

<p>As a part of data exploration, I tried to dig into the data to get some insights. Here are some of the interesting insights that I could gather, rest of them are plotted in the notebook.</p>

<h6 id="insight-1---busiest-times-of-the-day">Insight 1 - Busiest times of the day</h6>

<p><img src="/images/NYC_cabs_data/hourwise_dist.png" alt="placeholder" style="margin:auto; display:inline; float:right;" />
It starts to drop off sharply at 12 in the night, picks up in the day around morning 8, slackens a bit towards late afternoon, and then peaks at 7 in the night.
<br />
<br />
<br />
<br />
<br />
<br /></p>
<p></p>

<h6 id="insight-2---busiest-locations-in-the-city">Insight 2 - Busiest locations in the city</h6>

<p><img src="/images/NYC_cabs_data/locations.png" alt="placeholder" style="margin:auto; display:block; " />
<br />
<br />
The busiest location in the city happens to be an area of 1 sq km  around Park Avenue in Manhattan, NYC ( I’ve never been to NYC, just guessing from top 10 busiest locations in NYC, Manhattan seems to be the most happening place !)</p>

<h6 id="insight-3---non-gaussian-fare--tips-distribution">Insight 3 - Non-Gaussian fare &amp; tips distribution</h6>

<p>Regarding the fare distribution, I was <em>expecting a Gaussian distribution but to my surprise it turned out to be a Poisson.</em> The other more interesting insight was that that in tips the median was roughly 25% of the fare amount. Also, look at the outlier in the tip amount, it goes as high as $200 (that makes suddenly the driving business so lucrative !)</p>

<p><img src="/images/NYC_cabs_data/fare_dist.png" alt="placeholder" style="margin:auto; display:inline; float:right;pad:50px;" /></p>

<p><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br /></p>
<p></p>

<h6 id="insight-4---monday-blues-">Insight 4 - Monday blues !</h6>

<p><img src="/images/NYC_cabs_data/daywise_dist.png" alt="placeholder" style="margin:auto; display:block; float:right;" />
Interestingly , looking at the patterns of trips for each day of the month, it’s clearly evident that Mondays of the month (1,8,15,22,29) are days with least no of trips . Though 1st was just after Easter Weekend, so presumably the least no. of trips that days justifies for itself.</p>

<p><br />
<br />
<br /></p>

<h3 id="going-into-optimization-problem">Going into optimization problem</h3>

<p>The first problem was the data was too huge for me to work on my laptop in a small time-frame. So with loss of generality, I cut down on the size by choosing the least, sampling just a single day’s data for purpose of optimizing the revenue of cab-driver.</p>

<p>Though the algo can very well be generalized to any number of day’s data if required. There were a few basic assumptions that I had to carve out for myself for estimating the revenue generation.</p>

<h4 id="the-assumptions">The Assumptions</h4>
<ul>
  <li>The grid chosen above would be fairly good representation of the dynamics of NYC  and that’s because 1 lat ~ 112 km and 1 long ~ 90 km (at 40 degree lat), so the chosen grid ~600sq km contains &gt;90% of the overall rides</li>
  <li>For optimization of earnings, I have optimized fare amount earnt and not total amount</li>
  <li>There’s a linear relationship between trip fare and trip time, which is to a good extent true, as I could fit a linear regression curve with linear, square &amp; cubic coefficients for time(in minutes) and the coefficients were orders of magnitude separate, proving it’s a linear relationship. (Appendix 2 in the Notebook)</li>
  <li>It’s assumed a driver can choose his own route i.e. find a customer always depending on the route he chooses</li>
  <li>The demand, fare, and trip time for any route and any pickup region don’t vary much within an hour and central measure is a good approximations</li>
  <li>Given there was no information on supply of cabs at a location, it was assumed to be proportional to demand. Hence the probability of getting a cab was assumed uniform, only the demand was checked for a threshold (higher than 20% of the median demand across all regions)
<br /></li>
</ul>

<h4 id="the-equations">The Equations</h4>
<p><img src="/images/NYC_cabs_data/linear_quations.png" alt="placeholder" style="margin:auto; display:block;float:right;" /></p>

<p><br />
<br />
<br />
<br />
<br />
<br />
<br /></p>

<p>In the above equation point to be noted is the</p>

<p><code class="highlighter-rouge">total_time_travelled = trip time - stationary_minutes</code></p>

<p>For going from Step 2 to Step 3, the assumption (mentioned in the footer and proved in <em>Appendix</em>) would work fine.
So from the above equations it is clear that for a cab driver to optimize his earning, he would need to optimize for 2 parameters given he has a fixed trip time</p>

<ol>
  <li>Mean fare per min - The cab should ideally operate on routes that have the maximum fare per min at that hour</li>
  <li>Trip_time - That is, the cab should never stop in the entire duration. Ideally it should be traveling into demand regions with a minimum demand</li>
</ol>

<p>Thus to take care of the point 2, check for the last assumption - only places with demand greater than 20% (a heuristics based threshold) median demand were considered as possible candidate locations for next trip in the optimization algorithm. If we have supply information, this could be modeled even better. Rest of the optimization algorithm boils down to maximizing point 1, i.e. Mean fare per min.</p>

<p>The pseudo algorithm would go something like this</p>

<ol>
  <li>If starting the day, then search for the region with highest mean fare per min and drive till there before you start the day</li>
  <li>If drive needs to go to next day, beyond 23:59, make necessary adjustments</li>
  <li>For selecting the itinerary apply recursively the function to select next best route if end_time is not crossed is as follows
    <ul>
      <li>For selecting next route,
        <ol>
          <li>List all the  drop-off locations for which people have used cabs at the start_locaton at the start_time</li>
          <li>Calculate  the time taken to travel to each of the locations</li>
          <li>Check for the demand at each of the locations and check if they are above the threshold (20% of median of threshold)</li>
          <li>Check for the best mean_fare per min across all the routes and choose the best</li>
          <li>Calculate the time of travel &amp; estimated fare based on data</li>
          <li>After reaching the dropoff location,adding a 3 mins for transaction, next route selection algo is applied again  </li>
        </ol>
      </li>
      <li>If there’s no demand for any cab at the current location (normally happens around late_night) or demand below threshold at all possible dropoff locations
        <ol>
          <li>Do a 1 degree search for the nearest square on grid which has demand</li>
          <li>For multiple regions with demand, choose the region with best “mean fare per min” route starting from that region</li>
          <li>Estimate the time of travel to the region chosen above and add no fare to the corresponding journey</li>
          <li>If no region found having demand in 1-degree search, keep on increasing degree of search till the best location is found</li>
        </ol>
      </li>
    </ul>
  </li>
</ol>

<h3 id="time-for-results">Time For Results</h3>

<p>So, now checking for the efficiency of optimisation algorithm, the benchmark is -  a normal cab driver earns trip_fare of $177 (median) in roughly 6 hours (median)</p>

<h5 id="insight-5---hardworking-and-rich-driver">Insight 5 - Hardworking and rich driver</h5>

<p><img src="/images/NYC_cabs_data/optimised_revenue.png" alt="placeholder" style="margin:auto; display:block;" />
The graph above shows are the fares a cab driver could earn starting out at different hours in the day using the optimisation algorithm described above (assuming he works for the median duration 6 hours).The red line marks the median fare of $177 earnt by most of the cab drivers. As is evident, the optimisation algorithm would help in earning almost every time in earning way more than the median amount.</p>

<p>And as it turns out if he starts at 12 noon and continues till 6 in the evening, he would earn $380 using the optimisation algorithm, which is <strong>2.16 times more than the median fare</strong> earned by a cab driver in NYC, working for 6 hours.</p>

<h5 id="insight-6---efficient-but-lazy-driver">Insight 6 - Efficient but lazy driver</h5>

<p><img src="/images/NYC_cabs_data/optimised_time.png" alt="placeholder" style="margin:auto; display:block;" />
The graph above depicts the time taken by a cab driver to earn the median fare of $177 using the optimisation algorithm described above, starting at different hours of the day. The red line marks the median time of 6 hours taken by most of the cab drivers.As is evident here also, the optimisation algorithm would minimise the time almost every time to way below 6 hours.</p>

<p>For a driver who is lazy and just wants to earn the median fare amount ($177) in quickest possible time, it turns out, if the driver starts at 8AM, he can earn the $207 in just <strong>2 hrs 33 mins, compared to 6 hours</strong> for majority of the rest of the drivers</p>

<h3 id="conclusions">Conclusions</h3>

<p>As is evident, from the above cases, the optimisation algorithm performs quite good. Though something that baffled me was why despite peaking of traffic in the evening from 18:00 -22:00 (see the busiest hours plot in the start) , it seems that as a cab driver you’re not going to make much of money starting  say around 19 and driving for 6 hours as compared to starting at 12:00 hours. Also, if you’re a lazy driver, you’re going to take a lot more time to make $177 than starting at 12:00 hours.</p>

<p>The reason lay evident on digging a bit more into the data. Looking at the trip_distance distribution at these 2 times, it’s clear that the extra traffic peak at 19:00 hours, seems to be coming from a lot of short distance trips. In fact, frequency of trips with 10km or higher is lower at 19:00 hours.</p>

<p><img src="/images/NYC_cabs_data/distance_12.png" alt="placeholder" style="margin:auto; display:inline; width:50%;height:auto;float:left;" />
<img src="/images/NYC_cabs_data/distance_19.png" alt="placeholder" style="margin:auto; display:inline; width:50%;height:auto;float:right;" /></p>

<p><br />
<br />
<br /></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="//2016/09/17/unsupervised-learning-way-forward/">
        Is unsupervised learning the way forward ?
      </a>
    </h1>

    <span class="post-date">17 Sep 2016</span>

    <p>Of late, we have heard a lot of talk about unsupervised learning being the way forward.
Before we delve further, let’s clear the air around the types of learning.</p>

<p><strong>Supervised learning</strong> : Learning, wherein the model is provided with target labels.
The model is trained to predict the labels. E.g. Detecting digit from a hand-written image,
given similar training data with labels (i.e. mapping of every image in training set to a corresponding label)</p>

<p><strong>Unsupervised learning</strong> : Exact opposite of above, that is, no labels are provided for training.
E.g. Detecting from various images of hand-written digits, images of ‘1’ &amp; ‘7’ are different categories.</p>

<p>There is another category - semi-supervised learning. More on it later. So unsupervised seems easy, right ? So
exactly why this hype around unsupervised learning ?</p>

<p style="color:gray; font-size: 80%; text-align: center;"><img src="/images/unsuper-vs-super.png" alt="placeholder" style="margin 0 auto; display:block;" />
Fig: No. of ICML papers on supervised &amp; unsupervised learning</p>

<p>Well, going by trends of ICML papers (pic above), it very well proves that focus of all the deep learning research has been around supervised learning all this while. Apparently it turns out that unsupervised learning could in fact actually be holding the key to future. Reasons being</p>

<ol>
  <li>
    <p><em>Anotation is costly and hence rare</em> - Annotation refers to labelling such as marking out the boundary of each pet in a picture of pets and then labelling them with corresponding category of pet. Hence, annotation for images and text is costly because of higher man-hours needed to annotate each example.  Even though annotation platforms like <a href="https://www.mturk.com/mturk/welcome">AMT</a> have arrived to rescue, annotated datasets are tough to obtain for most of the applications</p>
  </li>
  <li>
    <p><em>Pre-training to reduce dimensionality</em> : As anyone slightly familiar with training nets would confirm, converging deep supervised nets is tougher in higher dimension space - mostly because of overfitting in a large parameter space. As per <a href="http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf">findings</a> by Prof Begio, models that start off with some unsupervised learning to reduce dimensionality tend to have lower variance. Hence, those models are more robust to random initialisations. He illustrates in the paper, models that start with parameters learnt from unsupervised nets tend to lock in parameter spaces which aren’t achievable by supervised nets and vice-versa</p>
  </li>
  <li>
    <p><em>Supervision not desirable</em> : For a lot of use-cases like generating images, generating audio  - there’s really no ‘correct’ answer. To replicate human-like capabilities like creativity, behavior with other machines - where we want to simulate human like capabilities in civilisation of machines - it’s desirable that the machines aren’t trained with a correct way of behavior, as that defeats the purpose of simulation</p>
  </li>
  <li>
    <p><em>Labelling not accurate</em> - As humans we do err. When it comes to easier object segmentation like cat, dog - there’s hardly any error. But when it comes to annotation of complex bio-medical images it isn’t easy for trained radiologists to annotate easily. So for most labelled public datasets, labelling is done multiple times over by separate viewers and majority vote is taken for final categorisation.</p>
  </li>
</ol>

<p>So given that we understand the importance of unsupervised learning, let’s have a look at some of the most popular unsupervised algorithms in various fields of applications.</p>

<h3 id="word-embedding">Word Embedding</h3>

<dl>
<dt>Applications</dt>
<dd>Word2Vec is normally used for building semanti representation of words in a latent space based on features such as occurrence of a word in a sentence, co-occurrence with other words etc. </dd>
<dt>Architecture</dt>
<dd>Word embedding algorithms like Word2Vec use shallow 2 layer neural networks, that take in a corpus of input and produces a vectorial representation of each word in some high-dimensional latent space. The algorithm learns from a semantic vectorial representation of each of the words. It can thus easily predict</dd>
<dt>Variants</dt>
<dd>Doc2Vec, GloVe</dd>
</dl>
<div class="message">
  V<sub>King</sub> - V<sub>Man</sub> + V<sub>Woman</sub> ~ V<sub>Queen</sub>
</div>
<p><img src="/images/skip_gram_net_arch.png" alt="placeholder" class="center-image" /></p>

<h3 id="autoencoders">AutoEncoders</h3>

<dl>
<dt>Applications</dt>
<dd>For pre-training purposes, the output of the encoder (in a much lower dimension space) is generally used as a good proxy for the original input</dd>
<dt>Architecture</dt>
<dd>AutoEncoders generally contain 2 parts to the architecture - encoders and decoders, placed sequentially. They are trained to predict the input itself. Encoder part takes in the raw input and downsamples in successively lower dimensional space as the no of neurons in each layer goes down with increase in layer depth. Decoder part takes in the output of encoder and upsamples into higher dimensional space successively as neurons in each layer increases with depth. Final output of decoder is in the same dimension as the input given to the encoder. </dd>
<dt>Variants</dt>
<dd>Variaional AEs, Denoising AEs </dd>
</dl>

<p><img src="/images/ae.png" alt="placeholder" class="center-image" /></p>

<h3 id="generative-adversial-networks">Generative Adversial Networks</h3>

<dl>
<dt>Applications</dt>
<dd>GANs are normally used for generating dreams, filling in missing patches of images, extrapolating background from images.</dd>
<dt>Architecture</dt>
<dd>Generative Adversial Nets generally also consists 2 parts - generator networks and discriminator nets. The generator nets generates say images from just Gaussian noise signal as input. The discriminator is shown the output from generator net along with 'real' images and trained to discriminate between real and 'fake generated' images. The error signal from prediction is backpropagated back through the gnerative net as well. Thus over the epochs, the discriminator becomes good at identifying 'real' from 'fake generated' images while generator net becomes good at generating a near-real image.</dd>
<dt>Variants</dt>
<dd>DCGAN, GAN </dd>
</dl>
<p><img src="/images/gan.png" alt="placeholder" class="center-image-wide" /></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="//2016/09/05/AI-beyond-buzzwords/">
        AI - Beyond Buzzwords & Comparisons To Human Abilities
      </a>
    </h1>

    <span class="post-date">05 Sep 2016</span>

    <p>Any heated argument on AI these days soon ends up in a predictable trajectory - so DeepMind’s AlphaGo beats Go champ, Tesla to compete with Uber using AI driven cars, ethical dilemma of driver-less cars and finally - would robots overpower humankind (on sidelines of the last debate would be venue of the Matrix themed D-Day - Earth or Mars !)</p>

<p>So if you’re writing a sci-fi book or you’re a tarot-reader then don’t bother to read further.
But, if you’re reading buzzwords everyday and wondering what’s AI, what’s the big deal about it and where we stand as of today compared to human-like capabilities of AI; may be give the post a read.</p>

<h3 id="what-is-ai--what-is-not-">What is AI &amp; what is not ?</h3>

<p>AI, coined in 1956 at University of DartMouth by psychologist Rosenblatt,
was defined vaguely as a field aimed to make machines do the same work as humans.
In the years to follow, conventional Machine Learning (ML) algorithms became norm of the day in AI till
something strangely powerful happened in 2012. This was the ImageNet (an image recognition competition)
breakthrough by Prof. Hinton (in Google now) and his students based on Le Net, a Convolutional Net originally
designed by Le Cunn (in FB now), the-then prof at NYU.
This breakthrough was strange cause till then Convolutional Nets (CNNs) had hardly shown any usefulness
beyond hand-written character recognition (here’s a <a href="https://www.youtube.com/watch?v=FwFduRA_L6Q">video</a> on Le Cunn training CNN
back in ‘93 at Bell Labs) and yet it was powerful  as it  entailed an explosion in AI over
the coming years in ways people in academia and industry had hardly foreseen. See the figure below.</p>

<p style="color:gray; font-size: 80%; text-align: center;"><img src="/images/newplot.png" alt="NIPS &amp; ICML Papers submitted" title="NIPS &amp; ICML Papers submitted" />
Fig: No. of research papers accepted in major AI/ML conferences</p>

<p>To put it simply, AI agents learn from data, preferably huge amounts of data - instead of programmer himself hard-coding and modelling reactions to various use cases. The idea is</p>

<blockquote>
  <p>Don’t model the World but model the Brain and only then let the modelled Brain learn.</p>
</blockquote>

<p>Modelled after brain, in it’s simplest avatar, a net essentially consists of a graph of nodes which processes input sequentially. By ‘processing’ I meant multiplying output from previous node by a weight matrix and applying non-linearity to the product. Learning the weight matrices is the whole game !</p>

<p>Also, it’s not data mining where the pattern is mined from data and then requisite changes are made in the algorithm as per observed pattern. AI is more end-to-end. So when I see a lot of startups using smart but hard-coded logic based algorithms (based on data or otherwise) under alias of AI, I feel it’s gravely misleading.</p>

<h3 id="why-the-hype-around-ai-this-time-around-">Why the hype around AI this time around ?</h3>

<p>Interestingly, after perceptrons were introduced in 1956, it was followed by immense hype regarding it’s capabilities, sort of what we see around AI now. And sadly, there was a lot of disappointment that followed it. In fact, there were couple of AI winters in the intermediate years. (‘74-‘80 &amp; ‘87-‘93)</p>

<p>The reasons, both time around, were lack of computational power, coupled with cuts in funding because of economic crashes. Post ’93 even though it regained some lost ground following Le Cunn’s success in handwritten digit recognition, it wasn’t until 2012 that using nets became mainstream, again.</p>

<h4 id="so-whats-happening-right-this-time-around-">So what’s happening right this time around ?</h4>

<p>The nets that were hardly 10 layers deep pre-2012, can now reach 1000 layers easily without much trouble in training. Deeper nets kicked off the field of Deep Learning - the deeper the nets, the better the results tend to be in general. The reasons are majorly -</p>

<ul>
  <li><em>Higher computational powers</em>: The computational gains because of advent of GPU and parallelised computation was a major force behind the boom of AI this time. In fact, parallelised computation was the recipe for Prof. Hinton’s Image Net success in 2012.</li>
  <li><em>Data, enormous data</em>: Most importantly, the sole reason AI has seen success beyond expectations has been availability of data - something that could’ve only happened in post-internet, post-Google &amp; post-FB era.</li>
  <li><em>Funding</em>: Apart from the above reasons, the amount of money that has been flowing intp AI in the current boom has been phenomenal- the funding for AI based startups has been pegged somewhere at $310mn for the year 2015.</li>
</ul>

<p style="color:gray; font-size: 80%; text-align: center;"><img src="/images/AI_quarterly_finance_20160203.jpg" alt="Funding in AI Space" />
Fig : Funding in AI based startups taken from CB Insights article</p>

<h3 id="what-ai-can-and-what-it-cant">What AI can and what it can’t</h3>

<p>Apparently, AI is pretty good when it comes to visual recognition tasks - take for example - a net that <a href="http://cs231n.stanford.edu/reports2016/022_Report.pdf">detects sentiment from facial expression</a> (the GIF below, taken from YouTube video demo of HappyNet) or one that can do  stuff such as- make any <a href="http://sites.skoltech.ru/compvision/projects/deepwarp/">celeb gaze whichever way you like</a></p>

<p>So when it comes to comparing with human performance in Computer Vision (object detection from images), AI has been able to recognise with 6.8 % error central objects in images compared to humans (the human being researcher Andrej Karapathy himself) with 5.1 % error. When it comes to semantically segmenting out objects from images, recent breakthroughs such as U-Nets are showing some great potential but they involve a lot of supervision costs (i.e. pixel-by-pixel labelling) except this very <a href="https://arxiv.org/abs/1506.02106">recent paper</a> by Stanford Prof. Li Fei-Fei. Even though from advent of AI-driven cars, it could seem that AI has conquered computer vision, but it is very far from over. In fact, there are <a href="http://arxiv.org/pdf/1606.03556v2.pdf">papers</a> which prove that machines see quite differently from human beings.</p>

<p>In speech recognition as well, AI has been pretty good (with less than 8% error on vocabulary consisting of all alphabets and numbers). AI has been exceptional at playing strategy games such as Chess, AlphaGo. Also, at <a href="http://blog.qure.ai/">Qure</a>, we can see AI performing better than some physicians on medical diagnosis, something also <a href="http://www.wired.co.uk/article/ibm-watson-medical-doctor">reported by IBM’s Watson</a> as the underlying tasks involve visual recognition and segmentation tasks at their core.</p>

<p>Even AI is able to <a href="http://deepdreamgenerator.com/">dream</a> and generate images on its own - in a sense it can develop a sense of creativity - through a technique known as <strong>adversial training</strong>. Though it’s not like the creativity we have - to think about objects that never existed. The kind of creativity that AI displays is on the lines of being able to predict a picture correctly when the picture’s central part is cropped, after obviously having seen similar images during training.</p>

<p>But when it comes to basic comprehension tasks like bAbI tasks or MC Tests- answering based on comprehensions like -  “Sandra travelled to the office.Sandra went to the bathroom. Where is Sandra? “ AI still lags behind (around ~60% accuracy without supervision, that is when the AI isn’t supplied with any info on where in the comprehension to look for answer vs ~70% accuracy when it’s provided with the cues). Also, when it comes to answer questions based on picture, or  word-sense disambiguation or Named Entity Recognition ( recognising from “Jack was playing tennis yesterday” - that Jack is a person, tennis is a sport and yesterday is time) AI has not been anywhere close to human level accuracy.</p>

<h2 id="concluding-thoughts">Concluding thoughts</h2>

<p>So that was AI-101, with a peek into world of AI and the truth behind it. So while AI can generate some music, predict the <a href="http://www.mirror.co.uk/tech/meet-artificial-intelligence-knows-whos-7806263">next person dying on popular TV series GoT</a>, save the <a href="http://www.huffingtonpost.in/entry/detecting-ignition-of-wildfires-sooner_b_8028786">world from wildfire</a>, <a href="http://www.geekwire.com/2016/patook-llc/">detect flirting from chats</a> - but currently it has got some serious limitations as well. Well, Artificial Narrow Intelligence (ANI) , Artificial General Intelligence (AGI) &amp; Artificial Super Intelligence (ASI) may be good for hypothetical discussions, in reality it’s probably far-fetched as of today. The boom in AI is real for sure, but the hysteria around AI not so much. And this is something important to remember because the first AI winter was a result of the immense hysteria around perceptrons followed by huge disappointment. If we want to avoid something similar this time, then all of us - researchers, practitioners, investors etc.- need to have realistic expectations in line with current state-of-art research. Obviously, AGI is not impossible in long run given the way things are changing everyday, but if you’re fearing a robot takeover soon or betting your money on AGI taking over on chat bots, it may be a good idea to just sit back and think again.</p>

<p><strong>P.S.</strong> : If you are a Deep Learning Scientist reading this, and are interested for a challenging as well as impacting role at qure.ai , write to us quickly.</p>

<p>If you’re a startup founder reading this and need help in brainstorming the right AI path for your startup given current advances, feel free to contact me. More than happy to help !</p>

<p><strong>P.P.S.</strong> : All the opinions expressed above are my personal opinions, and don’t reflect by any means opinion of Qure or any other firm mentioned above.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="//2016/03/15/solving-for-X-in-Tinder-for-X/">
        Why Tinder works? Solving for X in Tinder for X (Part 2/2)
      </a>
    </h1>

    <span class="post-date">15 Mar 2016</span>

    <p>In <a href="https://www.linkedin.com/pulse/why-tinder-works-insights-how-build-addictive-products-nivedan-rathi">Part 1</a>, we delved into the user psychology of what makes Tinder such an addictive product and what are its takeaways for your business idea in general. We’ve all heard a lot about the Uber for X model now, where X has been abused and overused a lot (2016 is an especially interesting time for these startups). Let’s talk about the other cool thing - Tinder for X. So we ventured out to find what makes or break a Tinder for X model where X could be different industries like recruitment, shopping etc.</p>

<p>Let’s begin with all the major criteria for any business problem to be suited for Tinder for X model</p>

<ul>
  <li>Should connect 2 communities who need each other</li>
  <li>Availability of almost infinite options to swipe for both communities</li>
  <li>Any wrong decisions should have little downside</li>
  <li>Snap judgement to proceed to the next meaningful step should be possible</li>
  <li>Very little but highly significant information must be presented</li>
  <li>Choices should be ideally binary &amp; execution virtually zero effort (Tinder-swipe)</li>
  <li>Should offer variability in rewards</li>
  <li>Should trigger the emotion of ego boost from a “match”</li>
</ul>

<p>Now, let’s look at some of the Tinder for X model, solving for X we get</p>

<dl>
<dt>X = Employer / Job-seeker | Major Apps : Super(India), Jobr</dt>

<dd>Looking for jobs had been made easier over the years but a Tinder-like model beats everyone in engagement. There are endless startup jobs &amp; an equal number of young grads on the app validate the effectiveness and need of the idea. Obviously, there’s also an ‘ego boost’ for an employee, as well as for the employer to some extent, whenever there’s a ‘match’.

However, it’s not a snap judgement for neither the employer nor the employee - it definitely takes second thoughts unless of course you’re in your notice period or the appraisal you’ve been waiting desperately for 2 years just went to someone else in the organisation. Moreover, the lack of Job Description only adds to the trouble. Also, for an employee, there’s definitely a lot of financial downside to a left swipe - that could mean a family holiday at Mauritius being just (s)wiped away!</dd>

<dt>X = Entrepreneur / Investor | Major Apps : Tendr , PIF</dt>

<dd>For investors sifting through a heap of startups daily, these apps are definitely a need of the hour for the investor community. Also, these apps levels field for ‘techie’ founders with limited networks. Obviously, the ‘ego boost’ exists predominantly for an entrepreneur whenever he gets a ‘right’ swipe from an investor.

Again, it would never be a snap judgement. Judging business potential isn’t as cognitive as judging people for hook-up, even for a seasoned investor. Forget business potential, even a beauty pageant where the sole job was to judge beauty by gazing- they ended up asking GK questions.

Also, an endless supply of investors would be tough. However, can’t comment same about no. of entrepreneurs in India these days. It’s only time till the Vijay Mallya raises investment for bail as well. Moreover, a high probability of financial downside for missing out a potential business idea for an investor makes snap judgement even harder.</dd>

<dt>X = Online shopper / online store | Major Apps: Mallzee. Hit or Miss</dt>

<dd>Definitely a must-have app for an ever deal-hungry consumer - what better than looking through an endless stack and dismissing based on % of discount. Given these days of deep-discounted customer acquisition strategy, judging based on discount is more cognitive than judging strangers.

However, this idea fails miserably on the ‘ego boost’ front. A store would never swipe left a customer, so basically it’s never a ‘match’ in the truest sense. Given a customer knows that he would always be swiped right, there’s no thrill or as such ‘variable reward’ (check the Part 1 for details)</dd>

<dt>X = News/ Home-hunt/ Food | Major Apps : InShorts, HomeSwipe, Nibbly</dt>

<dd>Let’s be clear at the outset, an app that gives you summarised news or affordable homes or delicious food doesn’t qualify, as we are talking about Tinder for X model. Sadly only if a news or a house or a biriyani could swipe you right and give you that ego boost then we were done here.

The lack of ‘variable rewards’ &amp; ‘ego boost’ makes this model not so attractive. It’s clearly a case of wrong nomenclature when someone calls something like ‘News In Shorts’ a Tinder for X model.</dd>

</dl>

<p>To conclude, all these are frankly our opinions &amp; judgements, backed by data. Any reference to any startups living or shut down are completely intentional but not ill-intended at all.</p>

<p>We feel that any product could be tweaked to be awesome, not necessarily in Tinder model.  Please feel free to contact us - me &amp; my co-author Nivedan in case you’re facing any challenge with your cool product and we can help you with designing a product strategy to make it even more awesome.</p>

<p>We would love to know more from you about what you think are the reasons for the success of Tinder and similar products. Also, any other A for B models would be a great topic to discuss.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div> -->



<div class="posts">
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2017/01/25/overlapping-chromosome-segmentation/">
        Segmenting Overlapping Chromosomes using Deep Learning
      </a>
    </h1>

    <time datetime="2017-01-25T00:00:00+05:30" class="post-date">25 Jan 2017</time>

    Deep Learning has been making quite a lot of progress in computer vision tasks of late. In this post, I go on to explain how to use 2D U Net (one of the most popular papers of 2015-16 in computer vision) for segmenting out overlapping chromosomes on a slide used for cytogenetics.

    
     <a href="/2017/01/25/overlapping-chromosome-segmentation/">Read more</a>
   

  </article>
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2016/12/10/NYC-cabs-data/">
        Optimising Cab Routes In NYC Using Data
      </a>
    </h1>

    <time datetime="2016-12-10T00:00:00+05:30" class="post-date">10 Dec 2016</time>

    In most of the cab rides I had my conversation with the cab owner tending towards to the ever-so-important question - “How to generate maximum revenue?” Do I drive at night? Where do I start my trip? What do I optimize for – longer rides in a longer time or repeated shorter rides in the same time? How long do I drive? and alike questions. This post tries to solve some of those questions along with bringing out some interesting insights about traffic in NYC.

    
     <a href="/2016/12/10/NYC-cabs-data/">Read more</a>
   

  </article>
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2016/09/17/unsupervised-learning-way-forward/">
        Is unsupervised learning the way forward ?
      </a>
    </h1>

    <time datetime="2016-09-17T00:00:00+05:30" class="post-date">17 Sep 2016</time>

    Of late, we have heard a lot of talk about unsupervised learning being the way forward. A lot of research at major R&D organisations like Open AI is focussed on unsupervised learning.Why is unsupervised learning so important ?

    
     <a href="/2016/09/17/unsupervised-learning-way-forward/">Read more</a>
   

  </article>
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2016/09/05/AI-beyond-buzzwords/">
        AI - Beyond Buzzwords & Comparisons To Human Abilities
      </a>
    </h1>

    <time datetime="2016-09-05T00:00:00+05:30" class="post-date">05 Sep 2016</time>

    Any heated argument on AI these days soon ends up in a predictable trajectory - so DeepMind's AlphaGo beats Go champ,Tesla to compete with Uber using AI driven cars, ethical dilemma of driver-less cars and finally - would robots overpower humankind (on sidelines of the last debate would be venue of the Matrix themed D-Day - Earth or Mars !)...if you’re reading buzzwords everyday and wondering what's AI, what's the big deal about it and where we stand as of today compared to human-like capabilities of AI

    
     <a href="/2016/09/05/AI-beyond-buzzwords/">Read more</a>
   

  </article>
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2016/03/15/solving-for-X-in-Tinder-for-X/">
        Why Tinder works? Solving for X in Tinder for X (Part 2/2)
      </a>
    </h1>

    <time datetime="2016-03-15T00:00:00+05:30" class="post-date">15 Mar 2016</time>

    In Part 1, we delved into the user psychology of what makes Tinder such an addictive product and what are its takeaways for your business idea in general... So we ventured out to find what makes or break a Tinder for X model where X could be different industries like recruitment, shopping etc.

    
     <a href="/2016/03/15/solving-for-X-in-Tinder-for-X/">Read more</a>
   

  </article>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2/">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

      </main>
      

      <footer class="footer">
        <small>
          &copy; <time datetime="2017-01-28T16:49:42+05:30">2017</time>. All rights reserved.
        </small>
      </footer>
    </div>

    
  </body>
</html>
